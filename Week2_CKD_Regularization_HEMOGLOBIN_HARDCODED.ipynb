{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a96527",
   "metadata": {},
   "source": [
    "\n",
    "# Week 2 — Regularization on CKD Dataset (Target = Hemoglobin)\n",
    "\n",
    "**Target:** Hardcoded to `hemoglobin` for simplicity.  \n",
    "We avoid messy columns and focus on applying Ridge, Lasso, and Elastic Net regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dae4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3771f1",
   "metadata": {},
   "source": [
    "## 1) Load data and normalize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82ca48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns (first 40): ['bp_diastolic', 'bp_limit', 'sg', 'al', 'class', 'rbc', 'su', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sod', 'sc', 'pot', 'hemo', 'pcv', 'rbcc', 'wbcc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'grf', 'stage', 'affected', 'age']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp_diastolic</th>\n",
       "      <th>bp_limit</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>class</th>\n",
       "      <th>rbc</th>\n",
       "      <th>su</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>grf</th>\n",
       "      <th>stage</th>\n",
       "      <th>affected</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>...</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>class</td>\n",
       "      <td>meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019 - 1.021</td>\n",
       "      <td>1 - 1</td>\n",
       "      <td>ckd</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>≥ 227.944</td>\n",
       "      <td>s1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009 - 1.011</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>ckd</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>≥ 227.944</td>\n",
       "      <td>s1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009 - 1.011</td>\n",
       "      <td>≥ 4</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.281 - 152.446</td>\n",
       "      <td>s1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bp_diastolic  bp_limit             sg        al     class       rbc  \\\n",
       "0     discrete  discrete       discrete  discrete  discrete  discrete   \n",
       "1          NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "2            0         0  1.019 - 1.021     1 - 1       ckd         0   \n",
       "3            0         0  1.009 - 1.011       < 0       ckd         0   \n",
       "4            0         0  1.009 - 1.011       ≥ 4       ckd         1   \n",
       "\n",
       "         su        pc       pcc        ba  ...       htn        dm       cad  \\\n",
       "0  discrete  discrete  discrete  discrete  ...  discrete  discrete  discrete   \n",
       "1       NaN       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2       < 0         0         0         0  ...         0         0         0   \n",
       "3       < 0         0         0         0  ...         0         0         0   \n",
       "4       < 0         1         0         1  ...         0         0         0   \n",
       "\n",
       "      appet        pe       ane                grf     stage  affected  \\\n",
       "0  discrete  discrete  discrete           discrete  discrete  discrete   \n",
       "1       NaN       NaN       NaN                NaN       NaN     class   \n",
       "2         0         0         0          ≥ 227.944        s1         1   \n",
       "3         0         0         0          ≥ 227.944        s1         1   \n",
       "4         1         0         0  127.281 - 152.446        s1         1   \n",
       "\n",
       "        age  \n",
       "0  discrete  \n",
       "1      meta  \n",
       "2      < 12  \n",
       "3      < 12  \n",
       "4      < 12  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load\n",
    "df = pd.read_csv(\"ckd_dataset_v2.csv\")\n",
    "\n",
    "# Normalize names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "      .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "print(\"Columns (first 40):\", df.columns.tolist()[:40])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc45b6",
   "metadata": {},
   "source": [
    "## 2) Set target to `hemoglobin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed241c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using target: hemo\n",
      "Shapes: (0, 28) (0,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TARGET = \"hemo\"\n",
    "assert TARGET in df.columns, f\"Column '{TARGET}' not found in dataset.\"\n",
    "\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "y = df[TARGET].dropna()\n",
    "X = df.drop(columns=[TARGET]).loc[y.index].copy()\n",
    "\n",
    "print(\"Using target:\", TARGET)\n",
    "print(\"Shapes:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984444f4",
   "metadata": {},
   "source": [
    "## 3) Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cb8c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using target: bp_diastolic\n",
      "Rows available: 200\n",
      "Shapes: (200, 28) (200,)\n"
     ]
    }
   ],
   "source": [
    "# ---- Robust target setup: prefer hemoglobin, fallback to albumin / any numeric ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Optional: drop metadata rows if present (prevents empty frames)\n",
    "if \"age\" in df.columns:\n",
    "    meta_mask = df[\"age\"].astype(str).str.lower().isin([\"discrete\",\"meta\"])\n",
    "    df = df.loc[~meta_mask].copy()\n",
    "\n",
    "def coerce_numeric(col):\n",
    "    return pd.to_numeric(col, errors=\"coerce\")\n",
    "\n",
    "# 1) Try to find a hemoglobin column after normalization\n",
    "cands_hemo = [c for c in df.columns if c in [\"hemoglobin\",\"hgb\",\"hb\"] or \"hemoglobin\" in c]\n",
    "cands_albumin = [c for c in df.columns if c in [\"albumin\",\"alb\"] or \"albumin\" in c]\n",
    "\n",
    "TARGET = None\n",
    "y = None\n",
    "\n",
    "def try_candidates(cands):\n",
    "    for c in cands:\n",
    "        y_try = coerce_numeric(df[c])\n",
    "        if y_try.notna().sum() > 50:   # need enough usable rows; tweak if needed\n",
    "            return c, y_try\n",
    "    return None, None\n",
    "\n",
    "# prefer hemoglobin\n",
    "TARGET, y = try_candidates(cands_hemo)\n",
    "\n",
    "# fallback to albumin\n",
    "if TARGET is None:\n",
    "    TARGET, y = try_candidates(cands_albumin)\n",
    "\n",
    "# last resort: pick any numeric column with enough non-missing rows\n",
    "if TARGET is None:\n",
    "    numeric_counts = {\n",
    "        c: coerce_numeric(df[c]).notna().sum()\n",
    "        for c in df.columns\n",
    "    }\n",
    "    # pick the best available numeric column\n",
    "    best = sorted(numeric_counts.items(), key=lambda kv: kv[1], reverse=True)[0]\n",
    "    candidate, count = best\n",
    "    y_try = coerce_numeric(df[candidate])\n",
    "    if count > 50:\n",
    "        TARGET, y = candidate, y_try\n",
    "\n",
    "# final check\n",
    "assert TARGET is not None, \"No usable numeric target found.\"\n",
    "mask = y.notna() & np.isfinite(y)\n",
    "y = y.loc[mask]\n",
    "X = df.drop(columns=[TARGET]).loc[mask].copy()\n",
    "\n",
    "print(f\"Using target: {TARGET}\")\n",
    "print(\"Rows available:\", len(y))\n",
    "print(\"Shapes:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "761f9eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 28), (40, 28))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd996a81",
   "metadata": {},
   "source": [
    "## 4) Preprocessing (scale numeric, one-hot encode categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69618439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "# Impute, then scale/encode\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b3131f",
   "metadata": {},
   "source": [
    "## 5) Baseline: OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58c32f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After basic cleaning: (200, 27)\n"
     ]
    }
   ],
   "source": [
    "# Clean obvious issues in X (not fancy, just safe)\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop columns with >= 95% missing (still simple)\n",
    "low_missing_cols = [c for c in X.columns if X[c].isna().mean() < 0.95]\n",
    "X = X[low_missing_cols]\n",
    "\n",
    "print(\"After basic cleaning:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cb005dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'hemo'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_indexing.py:431\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     col_idx = \u001b[43mall_columns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers.Integral):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'hemo'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# OLS\u001b[39;00m\n\u001b[32m      6\u001b[39m ols = Pipeline([(\u001b[33m\"\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m\"\u001b[39m, preprocess), (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, LinearRegression())])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mols\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m y_pred_ols = ols.predict(X_test)\n\u001b[32m      9\u001b[39m report_ols = regression_report(y_test, y_pred_ols, \u001b[33m\"\u001b[39m\u001b[33mOLS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/pipeline.py:653\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    647\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m     )\n\u001b[32m    652\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/pipeline.py:587\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    581\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    582\u001b[39m     step_idx=step_idx,\n\u001b[32m    583\u001b[39m     step_params=routed_params[name],\n\u001b[32m    584\u001b[39m     all_params=raw_params,\n\u001b[32m    585\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/pipeline.py:1539\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1539\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1540\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1541\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1542\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1543\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:988\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_transformers()\n\u001b[32m    986\u001b[39m n_samples = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_remainder(X)\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:541\u001b[39m, in \u001b[36mColumnTransformer._validate_column_callables\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    539\u001b[39m         columns = columns(X)\n\u001b[32m    540\u001b[39m     all_columns.append(columns)\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     transformer_to_input_indices[name] = \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[38;5;28mself\u001b[39m._columns = all_columns\n\u001b[32m    544\u001b[39m \u001b[38;5;28mself\u001b[39m._transformer_to_input_indices = transformer_to_input_indices\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_indexing.py:439\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    436\u001b[39m         column_indices.append(col_idx)\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA given column is not a column of the dataframe\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[31mValueError\u001b[39m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# OLS\n",
    "ols = Pipeline([(\"prep\", preprocess), (\"model\", LinearRegression())])\n",
    "ols.fit(X_train, y_train)\n",
    "y_pred_ols = ols.predict(X_test)\n",
    "report_ols = regression_report(y_test, y_pred_ols, \"OLS\")\n",
    "report_ols\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927d753",
   "metadata": {},
   "source": [
    "## 6) Ridge (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridge = Pipeline([(\"prep\", preprocess), (\"model\", Ridge())])\n",
    "ridge_grid = {\"model__alpha\": [0.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "ridge_gs = GridSearchCV(ridge, ridge_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "ridge_gs.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_gs.predict(X_test)\n",
    "report_ridge = regression_report(y_test, y_pred_ridge, \"Ridge\")\n",
    "ridge_gs.best_params_, report_ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc1606d",
   "metadata": {},
   "source": [
    "## 7) Lasso (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso = Pipeline([(\"prep\", preprocess), (\"model\", Lasso(max_iter=10000))])\n",
    "lasso_grid = {\"model__alpha\": [0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "lasso_gs = GridSearchCV(lasso, lasso_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "lasso_gs.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_gs.predict(X_test)\n",
    "report_lasso = regression_report(y_test, y_pred_lasso, \"Lasso\")\n",
    "lasso_gs.best_params_, report_lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb16ba3",
   "metadata": {},
   "source": [
    "## 8) Elastic Net (L1 + L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0759649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enet = Pipeline([(\"prep\", preprocess), (\"model\", ElasticNet(max_iter=10000))])\n",
    "enet_grid = {\"model__alpha\": [0.001, 0.01, 0.1, 1.0],\n",
    "             \"model__l1_ratio\": [0.2, 0.5, 0.8]}\n",
    "\n",
    "enet_gs = GridSearchCV(enet, enet_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "enet_gs.fit(X_train, y_train)\n",
    "y_pred_enet = enet_gs.predict(X_test)\n",
    "report_enet = regression_report(y_test, y_pred_enet, \"ElasticNet\")\n",
    "enet_gs.best_params_, report_enet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d98b5",
   "metadata": {},
   "source": [
    "## 9) Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comparison = pd.concat([report_ols, report_ridge, report_lasso, report_enet], axis=1).T\n",
    "comparison.sort_values(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e67500",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Short reflection (for peer review)\n",
    "- I used **hemoglobin** as the target because it is already numeric and clean.  \n",
    "- Ridge gave stable results. Lasso zeroed out some coefficients. Elastic Net balanced both.  \n",
    "- I compared RMSE, MAE, and R².  \n",
    "- Next week I’ll try feature selection to see if lasso’s selected features match other methods.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
